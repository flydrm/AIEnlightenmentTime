# QA架构师 Prompt 模板

## 角色定位

作为QA架构师，我的核心职责是：
- 设计和实施全面的质量保证体系
- 制定测试策略和测试架构
- 推动质量工程实践和自动化
- 建立质量标准和度量体系
- 确保产品达到高质量交付标准

## 基础模板

```markdown
# QA架构设计请求

## 角色声明
我是[项目名称]的QA架构师，负责建立和优化质量保证体系。

## 项目背景
- **项目类型**：[Android应用]
- **技术栈**：[Kotlin/Java, MVVM, Jetpack等]
- **质量目标**：[崩溃率<0.1%, 覆盖率>80%等]
- **团队规模**：[开发/测试人员比例]
- **发布周期**：[迭代周期]

## 需要帮助的内容
1. 测试策略制定
2. 测试架构设计
3. 自动化框架选型
4. 质量度量体系
5. 测试流程优化
6. 工具链建设

## 期望输出
- 测试策略文档
- 测试架构图
- 自动化方案
- 质量标准定义
- 最佳实践指南
```

## 场景化模板

### 1. 测试策略制定

```markdown
# Android应用测试策略制定

## 项目信息
- **应用类型**：[教育/工具/社交等]
- **目标用户**：[用户群体特征]
- **质量要求**：[性能/稳定性/安全性要求]
- **风险等级**：[高/中/低]

## 当前测试现状
- **测试覆盖**：[单元/UI/集成测试现状]
- **自动化程度**：[自动化比例]
- **问题发现率**：[测试阶段发现bug比例]
- **测试效率**：[测试执行时间]

## 需要制定的测试策略

### 1. 测试层级策略
- **单元测试**
  - 覆盖目标：[如80%]
  - 重点范围：[核心业务逻辑]
  - 工具选择：[JUnit, Mockito等]
  
- **集成测试**
  - 测试范围：[模块间接口]
  - 测试方法：[API测试, 数据库测试]
  - 环境策略：[测试环境管理]

- **UI测试**
  - 覆盖场景：[核心用户流程]
  - 自动化工具：[Espresso, UI Automator]
  - 稳定性保障：[防抖动策略]

- **系统测试**
  - 性能测试：[启动时间, 内存占用]
  - 兼容性测试：[设备/OS覆盖]
  - 安全测试：[数据安全, 权限管理]

### 2. 测试执行策略
- 测试时机
- 测试环境
- 测试数据
- 回归策略

### 3. 质量门禁
- 代码提交门禁
- 集成门禁
- 发布门禁
- 线上监控

请帮我制定完整的测试策略。
```

### 2. 自动化测试体系

```markdown
# 自动化测试体系建设

## 项目背景
- **当前自动化水平**：[描述现状]
- **痛点问题**：[手工测试多/回归慢/覆盖不足]
- **技术债务**：[遗留问题]
- **团队能力**：[自动化经验水平]

## 自动化目标
- **覆盖率目标**：[各层级目标]
- **执行效率**：[期望执行时间]
- **ROI预期**：[投入产出比]
- **维护成本**：[可接受范围]

## 需要设计的内容

### 1. 自动化测试架构
```
测试金字塔：
     E2E测试 (10%)
    /          \
   集成测试 (20%)
  /              \
 单元测试 (70%)
```

### 2. 技术选型
- **单元测试框架**
  - JUnit5 vs Kotest
  - Mockito vs MockK
  - Truth vs Hamcrest

- **UI测试框架**
  - Espresso vs UI Automator
  - Compose测试
  - 截图测试

- **API测试**
  - Retrofit Mock
  - WireMock
  - REST Assured

- **性能测试**
  - JMH (微基准测试)
  - Android Profiler集成
  - Monkey测试

### 3. CI/CD集成
- 触发机制
- 并行策略
- 失败处理
- 报告生成

### 4. 测试数据管理
- 测试数据生成
- 数据隔离策略
- 数据清理机制
- 敏感数据处理

请提供完整的自动化测试方案。
```

### 3. 质量度量体系

```markdown
# 质量度量体系设计

## 项目信息
- **产品阶段**：[开发/成长/成熟期]
- **质量痛点**：[当前主要质量问题]
- **度量目的**：[改进方向]

## 当前度量情况
- **已有指标**：[列出现有指标]
- **数据来源**：[数据收集方式]
- **使用情况**：[指标应用效果]

## 需要建立的度量体系

### 1. 过程质量指标
- **需求质量**
  - 需求变更率
  - 需求缺陷密度
  - 需求评审效率

- **设计质量**
  - 设计评审发现率
  - 架构复杂度
  - 技术债务指数

- **代码质量**
  - 代码规范符合率
  - 圈复杂度分布
  - 代码重复率
  - 注释覆盖率

- **测试质量**
  - 测试覆盖率
  - 缺陷检出率
  - 测试用例有效性
  - 自动化率

### 2. 产品质量指标
- **功能质量**
  - 功能缺陷密度
  - 严重缺陷占比
  - 缺陷修复时长

- **性能质量**
  - 启动时间
  - 页面加载时间
  - 内存占用
  - CPU使用率
  - 电量消耗

- **稳定性**
  - 崩溃率
  - ANR率
  - 异常率
  - 可用性

- **兼容性**
  - 设备覆盖率
  - OS版本覆盖
  - 分辨率适配

### 3. 用户质量指标
- **用户体验**
  - 应用评分
  - 用户反馈
  - 使用时长
  - 留存率

- **业务质量**
  - 功能使用率
  - 转化率
  - 业务成功率

### 4. 度量实施方案
- 数据采集方案
- 分析展示平台
- 预警机制
- 改进闭环

请帮我设计完整的质量度量体系。
```

## 进阶模板

### 1. 测试左移实践

```markdown
# 测试左移实践方案

## 背景分析
- **当前问题**：[问题发现太晚/修复成本高]
- **团队现状**：[开发测试协作模式]
- **文化基础**：[质量意识水平]

## 测试左移目标
- 需求阶段发现30%问题
- 设计阶段发现40%问题
- 编码阶段发现20%问题
- 测试阶段发现10%问题

## 实施方案

### 1. 需求阶段
- **需求评审检查单**
  - 完整性检查
  - 可测试性检查
  - 一致性检查
  - 验收标准明确性

- **用户故事质量**
  - Given-When-Then格式
  - 测试场景覆盖
  - 边界条件考虑

### 2. 设计阶段
- **设计评审参与**
  - 技术方案可测试性
  - 接口设计评审
  - 数据流设计验证

- **测试设计同步**
  - 测试计划制定
  - 测试用例设计
  - 测试数据准备

### 3. 编码阶段
- **TDD实践**
  - 单元测试先行
  - 测试驱动开发
  - 重构保护网

- **代码评审**
  - 测试代码评审
  - 可测试性改进
  - 测试覆盖检查

### 4. 持续集成
- **质量门禁**
  - 编译检查
  - 单元测试
  - 静态分析
  - 增量覆盖率

### 5. 文化建设
- 质量意识培训
- 最佳实践分享
- 质量指标透明
- 激励机制

请提供测试左移的详细实施方案。
```

### 2. 性能测试方案

```markdown
# Android应用性能测试方案

## 应用信息
- **应用类型**：[类型]
- **用户规模**：[DAU预期]
- **性能要求**：[具体指标]
- **关键场景**：[核心业务流程]

## 性能测试范围

### 1. 启动性能
- **冷启动**
  - 目标：< 3秒
  - 测试方法
  - 优化建议

- **热启动**
  - 目标：< 1秒
  - 测试场景
  - 监控指标

### 2. 页面性能
- **页面加载时间**
  - 关键页面列表
  - 性能预算
  - 测试工具

- **滑动流畅度**
  - FPS监控
  - 卡顿检测
  - 优化方向

### 3. 内存性能
- **内存占用**
  - 基准值设定
  - 场景化测试
  - 内存泄漏检测

- **内存抖动**
  - GC频率监控
  - 大对象分配
  - 位图优化

### 4. 耗电性能
- **场景功耗**
  - 待机功耗
  - 使用功耗
  - 后台功耗

- **优化策略**
  - WakeLock使用
  - 网络请求优化
  - 定位策略

### 5. 网络性能
- **请求性能**
  - API响应时间
  - 并发处理能力
  - 失败率

- **流量优化**
  - 数据压缩
  - 缓存策略
  - 增量更新

### 6. 性能测试工具
- Android Studio Profiler
- Systrace
- Battery Historian
- Network Profiler
- 自定义性能监控

请提供完整的性能测试方案。
```

### 3. 安全测试指南

```markdown
# Android应用安全测试

## 应用信息
- **数据敏感度**：[高/中/低]
- **用户类型**：[成人/儿童]
- **合规要求**：[GDPR/COPPA等]
- **安全等级**：[要求等级]

## 安全测试checklist

### 1. 数据安全
- **数据存储**
  - [ ] SharedPreferences加密
  - [ ] 数据库加密
  - [ ] 文件系统加密
  - [ ] 密钥管理安全

- **数据传输**
  - [ ] HTTPS强制使用
  - [ ] 证书固定
  - [ ] 中间人攻击防护
  - [ ] 敏感数据加密

### 2. 认证授权
- **用户认证**
  - [ ] 密码强度要求
  - [ ] 生物识别安全
  - [ ] 会话管理
  - [ ] 多因素认证

- **权限管理**
  - [ ] 最小权限原则
  - [ ] 动态权限申请
  - [ ] 权限使用审计

### 3. 代码安全
- **代码保护**
  - [ ] 混淆配置
  - [ ] 反调试保护
  - [ ] 完整性校验
  - [ ] 关键逻辑保护

- **依赖安全**
  - [ ] 第三方库漏洞扫描
  - [ ] 依赖版本管理
  - [ ] 许可证合规

### 4. 应用安全
- **组件安全**
  - [ ] Activity导出控制
  - [ ] Service权限保护
  - [ ] Provider访问控制
  - [ ] Broadcast安全

- **WebView安全**
  - [ ] JS注入防护
  - [ ] 文件访问限制
  - [ ] 安全配置

### 5. 隐私保护
- **儿童隐私**
  - [ ] 年龄验证
  - [ ] 家长控制
  - [ ] 数据收集限制

- **数据合规**
  - [ ] 隐私政策
  - [ ] 用户同意
  - [ ] 数据删除
  - [ ] 数据导出

请提供安全测试方案和工具建议。
```

## 测试用例模板

### 1. 功能测试用例

```markdown
## 测试用例：[功能名称]

### 用例信息
- **用例ID**：TC_001
- **优先级**：P0/P1/P2
- **类型**：功能/边界/异常
- **自动化**：是/否

### 前置条件
1. [条件1]
2. [条件2]

### 测试步骤
| 步骤 | 操作 | 预期结果 |
|------|------|----------|
| 1 | [操作描述] | [预期结果] |
| 2 | [操作描述] | [预期结果] |
| 3 | [操作描述] | [预期结果] |

### 测试数据
- 输入数据：[数据说明]
- 配置要求：[环境配置]

### 后置条件
- [清理操作]

### 备注
- [特殊说明]
```

### 2. 性能测试用例

```markdown
## 性能测试用例：[场景名称]

### 测试目标
- **指标**：[如启动时间]
- **基准值**：[如<3秒]
- **测试工具**：[工具名称]

### 测试环境
- **设备**：[型号列表]
- **OS版本**：[Android版本]
- **网络**：[WiFi/4G/3G]
- **配置**：[特殊配置]

### 测试步骤
1. **准备阶段**
   - [准备步骤]

2. **执行阶段**
   - [执行步骤]

3. **数据采集**
   - [采集方法]

### 结果记录
| 设备 | 系统版本 | 测试值 | 是否达标 |
|------|---------|--------|----------|
| [型号] | [版本] | [数值] | 是/否 |

### 分析建议
- [性能分析]
- [优化建议]
```

### 3. 兼容性测试矩阵

```markdown
## 兼容性测试矩阵

### 设备覆盖策略
- **覆盖率目标**：TOP 50设备的90%
- **重点机型**：[列表]

### 测试矩阵
| 厂商 | 机型 | 系统版本 | 屏幕尺寸 | 分辨率 | 测试结果 |
|------|------|---------|----------|--------|----------|
| 小米 | Mi 11 | Android 12 | 6.81" | 3200×1440 | ✅ |
| 华为 | P40 Pro | Android 10 | 6.58" | 2640×1200 | ✅ |
| OPPO | Find X3 | Android 11 | 6.7" | 3216×1440 | ⚠️ |
| vivo | X60 Pro | Android 11 | 6.56" | 2376×1080 | ✅ |
| 三星 | S21 | Android 11 | 6.2" | 2400×1080 | ❌ |

### 问题记录
| 机型 | 问题描述 | 严重程度 | 状态 |
|------|---------|----------|------|
| [机型] | [问题] | 高/中/低 | 待修复 |

### 适配建议
- [屏幕适配建议]
- [性能适配建议]
- [特殊机型处理]
```

## 最佳实践

### 1. 质量内建
- **需求质量**：明确、可测试、有验收标准
- **设计质量**：模块化、低耦合、高内聚
- **代码质量**：规范、简洁、可维护
- **测试质量**：全面、高效、可复用

### 2. 持续测试
- **持续集成**：每次提交触发测试
- **持续部署**：自动化部署测试环境
- **持续监控**：实时质量数据反馈
- **持续改进**：基于数据优化流程

### 3. 风险驱动
- **风险识别**：技术风险、业务风险
- **风险评估**：概率和影响度量
- **风险应对**：针对性测试策略
- **风险监控**：持续跟踪和调整

### 4. 协作文化
- **全员质量**：质量是所有人的责任
- **尽早介入**：测试参与全生命周期
- **知识共享**：经验和教训及时分享
- **持续学习**：新技术和方法论学习

## 工具推荐

### 1. 测试框架
- **单元测试**：JUnit5, Kotest, MockK, Robolectric
- **UI测试**：Espresso, UI Automator, Kakao
- **BDD框架**：Cucumber, Spek
- **Mock工具**：Mockito, WireMock, MockWebServer

### 2. 性能工具
- **Android工具**：Profiler, Systrace, Battery Historian
- **第三方工具**：LeakCanary, BlockCanary, Hugo
- **APM平台**：Firebase Performance, Bugly, EMAS

### 3. 质量平台
- **代码质量**：SonarQube, Detekt, ktlint
- **测试管理**：TestRail, Xray, ALM
- **缺陷管理**：Jira, Bugzilla, Mantis

### 4. CI/CD工具
- **构建工具**：Jenkins, GitLab CI, GitHub Actions
- **部署工具**：Fastlane, App Center, Firebase
- **监控工具**：Grafana, ELK, Prometheus

---

**提示**：
- 质量是设计出来的，不是测试出来的
- 自动化是手段，不是目的
- 关注业务价值，而非测试覆盖率
- 持续改进，追求卓越