#!/usr/bin/env python3
"""
æ™ºèƒ½éªŒè¯ç³»ç»Ÿ V4.0 - æ·±åº¦è¯­ä¹‰åˆ†æ + è¡Œä¸ºéªŒè¯
å½»åº•è§£å†³"å‡å®Œæˆ"é—®é¢˜
"""

import os
import re
import ast
import json
import subprocess
from typing import List, Dict, Set, Tuple, Optional
from dataclasses import dataclass, field
from enum import Enum
import networkx as nx

class IssueLevel(Enum):
    BLOCKER = "BLOCKER"      # é˜»å¡å‘å¸ƒ
    CRITICAL = "CRITICAL"    # å¿…é¡»ä¿®å¤
    MAJOR = "MAJOR"          # é‡è¦é—®é¢˜
    MINOR = "MINOR"          # æ¬¡è¦é—®é¢˜

@dataclass
class CodeIssue:
    file_path: str
    line_number: int
    issue_type: str
    description: str
    level: IssueLevel
    evidence: str
    suggestion: str
    confidence: float = 1.0

@dataclass
class FunctionAnalysis:
    name: str
    file_path: str
    has_implementation: bool
    calls_api: bool
    handles_errors: bool
    updates_ui: bool
    saves_data: bool
    has_return: bool
    dependencies: List[str] = field(default_factory=list)

class IntelligentValidator:
    def __init__(self, project_root: str = "/workspace"):
        self.project_root = project_root
        self.issues: List[CodeIssue] = []
        self.functions: Dict[str, FunctionAnalysis] = {}
        self.dependency_graph = nx.DiGraph()
        
    def validate(self) -> Dict:
        """ä¸»éªŒè¯å…¥å£ - å¤šç»´åº¦æ·±åº¦åˆ†æ"""
        print("\n" + "="*60)
        print("ğŸ§  æ™ºèƒ½éªŒè¯ç³»ç»Ÿ V4.0 - æ·±åº¦è¯­ä¹‰åˆ†æ")
        print("="*60 + "\n")
        
        # Phase 1: ä»£ç åˆ†æ
        print("ğŸ“Š Phase 1: ä»£ç ç»“æ„åˆ†æ")
        self.analyze_code_structure()
        
        # Phase 2: è¯­ä¹‰åˆ†æ
        print("\nğŸ” Phase 2: è¯­ä¹‰å®Œæ•´æ€§åˆ†æ")
        self.analyze_semantic_completeness()
        
        # Phase 3: ä¾èµ–åˆ†æ
        print("\nğŸ”— Phase 3: ä¾èµ–é“¾åˆ†æ")
        self.analyze_dependencies()
        
        # Phase 4: è¡Œä¸ºéªŒè¯
        print("\nğŸ¯ Phase 4: è¡Œä¸ºéªŒè¯")
        self.verify_runtime_behavior()
        
        # Phase 5: ä¸šåŠ¡é€»è¾‘éªŒè¯
        print("\nğŸ’¼ Phase 5: ä¸šåŠ¡é€»è¾‘éªŒè¯")
        self.verify_business_logic()
        
        # Phase 6: é›†æˆæµ‹è¯•
        print("\nğŸ”§ Phase 6: é›†æˆå®Œæ•´æ€§æµ‹è¯•")
        self.verify_integration()
        
        return self.generate_report()
    
    def analyze_code_structure(self):
        """åˆ†æä»£ç ç»“æ„ï¼Œå»ºç«‹å‡½æ•°å›¾è°±"""
        kotlin_files = self.find_kotlin_files()
        
        for file_path in kotlin_files:
            self.parse_kotlin_file(file_path)
    
    def parse_kotlin_file(self, file_path: str):
        """è§£æKotlinæ–‡ä»¶ï¼Œæå–å‡½æ•°ä¿¡æ¯"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # æå–æ‰€æœ‰å‡½æ•°
            function_pattern = r'(suspend\s+)?fun\s+(\w+)\s*\([^)]*\)(\s*:\s*[^{]+)?\s*\{([^}]*)\}'
            functions = re.finditer(function_pattern, content, re.DOTALL)
            
            for match in functions:
                is_suspend = match.group(1) is not None
                func_name = match.group(2)
                return_type = match.group(3)
                body = match.group(4)
                
                # åˆ†æå‡½æ•°ä½“
                analysis = FunctionAnalysis(
                    name=func_name,
                    file_path=file_path,
                    has_implementation=len(body.strip()) > 0,
                    calls_api='api' in body.lower() or 'service' in body.lower(),
                    handles_errors='try' in body or 'catch' in body or '.onFailure' in body,
                    updates_ui='_uiState' in body or '_state' in body or 'mutableStateOf' in body,
                    saves_data='save' in body or 'insert' in body or 'update' in body or 'dataStore' in body,
                    has_return='return' in body or (return_type and return_type.strip() != ': Unit'),
                    dependencies=self.extract_dependencies(body)
                )
                
                self.functions[f"{file_path}::{func_name}"] = analysis
                
                # æ£€æŸ¥ç©ºå®ç°
                if not analysis.has_implementation:
                    self.add_issue(
                        file_path=file_path,
                        line_number=0,
                        issue_type="empty_implementation",
                        description=f"å‡½æ•° {func_name} æ²¡æœ‰å®ç°",
                        level=IssueLevel.CRITICAL,
                        evidence=match.group(0)[:100],
                        suggestion="æ·»åŠ å®é™…çš„å®ç°é€»è¾‘"
                    )
                
        except Exception as e:
            print(f"âš ï¸ è§£ææ–‡ä»¶å¤±è´¥ {file_path}: {e}")
    
    def analyze_semantic_completeness(self):
        """è¯­ä¹‰å®Œæ•´æ€§åˆ†æ - æ£€æŸ¥åŠŸèƒ½æ˜¯å¦çœŸæ­£å®Œæ•´"""
        
        # 1. æ£€æŸ¥ViewModelçš„å®Œæ•´æ€§
        self.check_viewmodel_completeness()
        
        # 2. æ£€æŸ¥Repositoryçš„å®Œæ•´æ€§
        self.check_repository_completeness()
        
        # 3. æ£€æŸ¥å¯¼èˆªçš„å®Œæ•´æ€§
        self.check_navigation_completeness()
        
        # 4. æ£€æŸ¥APIè°ƒç”¨çš„å®Œæ•´æ€§
        self.check_api_completeness()
    
    def check_viewmodel_completeness(self):
        """æ£€æŸ¥ViewModelæ˜¯å¦å®Œæ•´å®ç°"""
        viewmodels = [f for f in self.functions.items() if 'ViewModel' in f[0]]
        
        for path_func, analysis in viewmodels:
            file_path = analysis.file_path
            
            # æ£€æŸ¥æ˜¯å¦æœ‰å¯¹åº”çš„UIçŠ¶æ€æ›´æ–°
            if analysis.calls_api and not analysis.updates_ui:
                self.add_issue(
                    file_path=file_path,
                    line_number=0,
                    issue_type="incomplete_ui_update",
                    description=f"{analysis.name} è°ƒç”¨äº†APIä½†æ²¡æœ‰æ›´æ–°UIçŠ¶æ€",
                    level=IssueLevel.CRITICAL,
                    evidence=f"Function: {analysis.name}",
                    suggestion="æ·»åŠ  _uiState.update æˆ– _state.value = ..."
                )
            
            # æ£€æŸ¥é”™è¯¯å¤„ç†
            if analysis.calls_api and not analysis.handles_errors:
                self.add_issue(
                    file_path=file_path,
                    line_number=0,
                    issue_type="missing_error_handling",
                    description=f"{analysis.name} ç¼ºå°‘é”™è¯¯å¤„ç†",
                    level=IssueLevel.MAJOR,
                    evidence=f"Function: {analysis.name}",
                    suggestion="æ·»åŠ  try-catch æˆ– .onFailure å¤„ç†"
                )
    
    def check_repository_completeness(self):
        """æ£€æŸ¥Repositoryå®ç°çš„å®Œæ•´æ€§"""
        repos = [f for f in self.functions.items() if 'Repository' in f[0]]
        
        for path_func, analysis in repos:
            # æ£€æŸ¥æ•°æ®æŒä¹…åŒ–
            if 'save' in analysis.name.lower() or 'update' in analysis.name.lower():
                if not analysis.saves_data:
                    self.add_issue(
                        file_path=analysis.file_path,
                        line_number=0,
                        issue_type="missing_persistence",
                        description=f"{analysis.name} å£°ç§°ä¿å­˜æ•°æ®ä½†æ²¡æœ‰å®é™…ä¿å­˜",
                        level=IssueLevel.CRITICAL,
                        evidence=f"Function: {analysis.name}",
                        suggestion="æ·»åŠ æ•°æ®åº“æˆ–DataStoreæ“ä½œ"
                    )
    
    def check_navigation_completeness(self):
        """æ£€æŸ¥å¯¼èˆªç›®æ ‡æ˜¯å¦éƒ½å­˜åœ¨"""
        nav_pattern = r'navigate\s*\(\s*["\']([^"\']+)["\']'
        screen_pattern = r'composable\s*\(\s*["\']([^"\']+)["\']'
        
        navigations = set()
        screens = set()
        
        for file_path in self.find_kotlin_files():
            with open(file_path, 'r') as f:
                content = f.read()
                
                # æ”¶é›†å¯¼èˆªè°ƒç”¨
                nav_matches = re.findall(nav_pattern, content)
                navigations.update(nav_matches)
                
                # æ”¶é›†å®šä¹‰çš„screen
                screen_matches = re.findall(screen_pattern, content)
                screens.update(screen_matches)
        
        # æ£€æŸ¥ç¼ºå¤±çš„screen
        missing_screens = navigations - screens
        for missing in missing_screens:
            self.add_issue(
                file_path="Navigation",
                line_number=0,
                issue_type="missing_screen",
                description=f"å¯¼èˆªç›®æ ‡ '{missing}' æ²¡æœ‰å¯¹åº”çš„Screenå®ç°",
                level=IssueLevel.BLOCKER,
                evidence=f"navigate('{missing}')",
                suggestion=f"åœ¨NavHostä¸­æ·»åŠ  composable('{missing}') {{ ... }}"
            )
    
    def check_api_completeness(self):
        """æ£€æŸ¥APIè°ƒç”¨çš„å®Œæ•´æ€§"""
        # æ£€æŸ¥æ‰€æœ‰å£°ç§°è°ƒç”¨APIçš„åœ°æ–¹æ˜¯å¦çœŸçš„æœ‰å®ç°
        api_functions = [f for f in self.functions.items() if f[1].calls_api]
        
        for path_func, analysis in api_functions:
            # è¯»å–å‡½æ•°ä½“
            with open(analysis.file_path, 'r') as f:
                content = f.read()
            
            # æ£€æŸ¥æ˜¯å¦æœ‰å®é™…çš„ç½‘ç»œè°ƒç”¨
            if 'suspend' in content and analysis.name in content:
                func_body = self.extract_function_body(content, analysis.name)
                
                # æ£€æŸ¥å¸¸è§çš„å‡å®ç°æ¨¡å¼
                fake_patterns = [
                    r'return\s+"[^"]+"\s*$',  # ç›´æ¥è¿”å›å­—ç¬¦ä¸²
                    r'return\s+\d+',          # ç›´æ¥è¿”å›æ•°å­—
                    r'return\s+true|false',   # ç›´æ¥è¿”å›å¸ƒå°”å€¼
                    r'delay\s*\(\s*\d+\s*\)', # åªæœ‰å»¶è¿Ÿ
                    r'return\s+.*Mock',       # è¿”å›Mockæ•°æ®
                    r'return\s+.*fake',       # è¿”å›fakeæ•°æ®
                    r'//\s*TODO',             # TODOæ³¨é‡Š
                    r'//.*implement',         # æœªå®ç°æ³¨é‡Š
                ]
                
                for pattern in fake_patterns:
                    if re.search(pattern, func_body, re.IGNORECASE):
                        self.add_issue(
                            file_path=analysis.file_path,
                            line_number=0,
                            issue_type="fake_implementation",
                            description=f"{analysis.name} å¯èƒ½æ˜¯å‡å®ç°",
                            level=IssueLevel.CRITICAL,
                            evidence=pattern,
                            suggestion="å®ç°çœŸå®çš„APIè°ƒç”¨é€»è¾‘",
                            confidence=0.8
                        )
                        break
    
    def analyze_dependencies(self):
        """åˆ†æä¾èµ–å…³ç³»ï¼Œç¡®ä¿é“¾æ¡å®Œæ•´"""
        # æ„å»ºä¾èµ–å›¾
        for func_key, analysis in self.functions.items():
            self.dependency_graph.add_node(func_key)
            
            for dep in analysis.dependencies:
                dep_key = self.find_function_key(dep)
                if dep_key:
                    self.dependency_graph.add_edge(func_key, dep_key)
        
        # æ£€æŸ¥æ–­é“¾
        for node in self.dependency_graph.nodes():
            if self.dependency_graph.out_degree(node) > 0:
                for neighbor in self.dependency_graph.neighbors(node):
                    if neighbor not in self.functions:
                        self.add_issue(
                            file_path=self.functions[node].file_path,
                            line_number=0,
                            issue_type="broken_dependency",
                            description=f"ä¾èµ–çš„åŠŸèƒ½ {neighbor} ä¸å­˜åœ¨",
                            level=IssueLevel.MAJOR,
                            evidence=f"{node} -> {neighbor}",
                            suggestion="å®ç°ç¼ºå¤±çš„ä¾èµ–åŠŸèƒ½"
                        )
    
    def verify_runtime_behavior(self):
        """éªŒè¯è¿è¡Œæ—¶è¡Œä¸º"""
        print("  - æ£€æŸ¥å¼‚æ­¥æ“ä½œ...")
        self.check_async_operations()
        
        print("  - æ£€æŸ¥çŠ¶æ€ç®¡ç†...")
        self.check_state_management()
        
        print("  - æ£€æŸ¥ç”Ÿå‘½å‘¨æœŸ...")
        self.check_lifecycle_handling()
    
    def check_async_operations(self):
        """æ£€æŸ¥å¼‚æ­¥æ“ä½œçš„æ­£ç¡®æ€§"""
        suspend_functions = [f for f in self.functions.items() if 'suspend' in f[0]]
        
        for path_func, analysis in suspend_functions:
            # æ£€æŸ¥æ˜¯å¦åœ¨æ­£ç¡®çš„scopeä¸­è°ƒç”¨
            with open(analysis.file_path, 'r') as f:
                content = f.read()
            
            if 'viewModelScope' not in content and 'lifecycleScope' not in content:
                if 'ViewModel' in analysis.file_path:
                    self.add_issue(
                        file_path=analysis.file_path,
                        line_number=0,
                        issue_type="missing_coroutine_scope",
                        description=f"å¼‚æ­¥å‡½æ•° {analysis.name} å¯èƒ½æ²¡æœ‰åœ¨æ­£ç¡®çš„scopeä¸­è°ƒç”¨",
                        level=IssueLevel.MAJOR,
                        evidence=f"Function: {analysis.name}",
                        suggestion="ä½¿ç”¨ viewModelScope.launch { ... }"
                    )
    
    def verify_business_logic(self):
        """éªŒè¯ä¸šåŠ¡é€»è¾‘çš„å®Œæ•´æ€§"""
        print("  - éªŒè¯ç”¨æˆ·æ•…äº‹...")
        self.verify_user_stories()
        
        print("  - éªŒè¯æ•°æ®æµ...")
        self.verify_data_flow()
    
    def verify_user_stories(self):
        """éªŒè¯å…³é”®ç”¨æˆ·æ•…äº‹æ˜¯å¦å¯ä»¥å®Œæˆ"""
        user_stories = [
            {
                "name": "ç”Ÿæˆæ•…äº‹",
                "required_chain": ["GenerateStoryUseCase", "StoryRepository", "StoryViewModel", "StoryScreen"],
                "required_features": ["api_call", "error_handling", "ui_update", "data_save"]
            },
            {
                "name": "å®¶é•¿ç™»å½•",
                "required_chain": ["ParentLoginViewModel", "ParentLoginScreen", "ParentDashboard"],
                "required_features": ["validation", "navigation", "state_management"]
            },
            {
                "name": "æ‹ç…§è¯†åˆ«",
                "required_chain": ["CameraScreen", "RecognizeImageUseCase", "ImageRecognitionRepository"],
                "required_features": ["camera_permission", "image_capture", "api_call", "result_display"]
            }
        ]
        
        for story in user_stories:
            print(f"    éªŒè¯: {story['name']}")
            missing_components = []
            
            for component in story["required_chain"]:
                found = False
                for func_key in self.functions:
                    if component in func_key:
                        found = True
                        break
                
                if not found:
                    missing_components.append(component)
            
            if missing_components:
                self.add_issue(
                    file_path="User Story",
                    line_number=0,
                    issue_type="incomplete_user_story",
                    description=f"ç”¨æˆ·æ•…äº‹ '{story['name']}' ç¼ºå°‘ç»„ä»¶: {missing_components}",
                    level=IssueLevel.BLOCKER,
                    evidence=str(missing_components),
                    suggestion="å®ç°ç¼ºå¤±çš„ç»„ä»¶ä»¥å®Œæˆç”¨æˆ·æ•…äº‹"
                )
    
    def verify_integration(self):
        """éªŒè¯é›†æˆçš„å®Œæ•´æ€§"""
        print("  - éªŒè¯ä¾èµ–æ³¨å…¥...")
        self.verify_dependency_injection()
        
        print("  - éªŒè¯APIé…ç½®...")
        self.verify_api_configuration()
        
        print("  - éªŒè¯æƒé™é…ç½®...")
        self.verify_permissions()
    
    def verify_dependency_injection(self):
        """éªŒè¯ä¾èµ–æ³¨å…¥çš„å®Œæ•´æ€§"""
        # æŸ¥æ‰¾æ‰€æœ‰@Inject
        inject_pattern = r'@Inject\s+(?:constructor|lateinit\s+var)\s+(\w+)'
        provides_pattern = r'@Provides.*fun\s+provide(\w+)'
        
        required_injections = set()
        provided_dependencies = set()
        
        for file_path in self.find_kotlin_files():
            with open(file_path, 'r') as f:
                content = f.read()
                
                # æ”¶é›†éœ€è¦æ³¨å…¥çš„
                injects = re.findall(inject_pattern, content)
                required_injections.update(injects)
                
                # æ”¶é›†æä¾›çš„
                provides = re.findall(provides_pattern, content)
                provided_dependencies.update(provides)
        
        # æ£€æŸ¥ç¼ºå¤±çš„ä¾èµ–
        # è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå®é™…åº”è¯¥æ›´æ™ºèƒ½
        missing = required_injections - provided_dependencies
        if missing:
            self.add_issue(
                file_path="Dependency Injection",
                line_number=0,
                issue_type="missing_dependency_provider",
                description=f"ç¼ºå°‘ä¾èµ–æä¾›è€…: {missing}",
                level=IssueLevel.MAJOR,
                evidence=str(missing),
                suggestion="åœ¨DIæ¨¡å—ä¸­æ·»åŠ @Providesæ–¹æ³•"
            )
    
    def extract_dependencies(self, body: str) -> List[str]:
        """ä»å‡½æ•°ä½“ä¸­æå–ä¾èµ–"""
        # ç®€åŒ–ç‰ˆæœ¬ï¼Œæå–å‡½æ•°è°ƒç”¨
        pattern = r'(\w+)\s*\('
        matches = re.findall(pattern, body)
        return [m for m in matches if m not in ['if', 'when', 'for', 'while', 'return']]
    
    def extract_function_body(self, content: str, func_name: str) -> str:
        """æå–å‡½æ•°ä½“"""
        pattern = rf'fun\s+{func_name}\s*\([^)]*\)[^{{]*\{{(.*?)\n\s*\}}'
        match = re.search(pattern, content, re.DOTALL)
        return match.group(1) if match else ""
    
    def find_function_key(self, func_name: str) -> Optional[str]:
        """æŸ¥æ‰¾å‡½æ•°çš„å®Œæ•´key"""
        for key in self.functions:
            if func_name in key:
                return key
        return None
    
    def find_kotlin_files(self) -> List[str]:
        """æŸ¥æ‰¾æ‰€æœ‰Kotlinæ–‡ä»¶"""
        kotlin_files = []
        for root, dirs, files in os.walk(os.path.join(self.project_root, "app/src/main")):
            dirs[:] = [d for d in dirs if d not in ['.git', 'build', '.gradle']]
            for file in files:
                if file.endswith('.kt'):
                    kotlin_files.append(os.path.join(root, file))
        return kotlin_files
    
    def add_issue(self, **kwargs):
        """æ·»åŠ é—®é¢˜"""
        issue = CodeIssue(**kwargs)
        self.issues.append(issue)
    
    def generate_report(self) -> Dict:
        """ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š"""
        # æŒ‰çº§åˆ«åˆ†ç±»
        blockers = [i for i in self.issues if i.level == IssueLevel.BLOCKER]
        criticals = [i for i in self.issues if i.level == IssueLevel.CRITICAL]
        majors = [i for i in self.issues if i.level == IssueLevel.MAJOR]
        minors = [i for i in self.issues if i.level == IssueLevel.MINOR]
        
        print("\n" + "="*60)
        print("ğŸ“Š éªŒè¯æŠ¥å‘Š")
        print("="*60)
        
        if blockers:
            print(f"\nğŸš« é˜»å¡é—®é¢˜: {len(blockers)} ä¸ª")
            for issue in blockers[:3]:
                print(f"  - {issue.description}")
                print(f"    æ–‡ä»¶: {issue.file_path}")
                print(f"    å»ºè®®: {issue.suggestion}")
        
        if criticals:
            print(f"\nâŒ ä¸¥é‡é—®é¢˜: {len(criticals)} ä¸ª")
            for issue in criticals[:3]:
                print(f"  - {issue.description}")
                print(f"    è¯æ®: {issue.evidence[:60]}...")
                print(f"    å»ºè®®: {issue.suggestion}")
        
        if majors:
            print(f"\nâš ï¸ é‡è¦é—®é¢˜: {len(majors)} ä¸ª")
            for issue in majors[:2]:
                print(f"  - {issue.description}")
        
        # ç»Ÿè®¡
        total_issues = len(self.issues)
        must_fix = len(blockers) + len(criticals)
        
        print(f"\nğŸ“ˆ ç»Ÿè®¡:")
        print(f"  - æ‰«æå‡½æ•°: {len(self.functions)} ä¸ª")
        print(f"  - å‘ç°é—®é¢˜: {total_issues} ä¸ª")
        print(f"  - å¿…é¡»ä¿®å¤: {must_fix} ä¸ª")
        
        # ç”ŸæˆJSONæŠ¥å‘Š
        report = {
            "success": must_fix == 0,
            "total_functions": len(self.functions),
            "total_issues": total_issues,
            "blockers": len(blockers),
            "criticals": len(criticals),
            "majors": len(majors),
            "minors": len(minors),
            "must_fix": must_fix,
            "issues": [
                {
                    "file": i.file_path,
                    "type": i.issue_type,
                    "description": i.description,
                    "level": i.level.value,
                    "suggestion": i.suggestion,
                    "confidence": i.confidence
                } for i in self.issues[:20]  # åªä¿å­˜å‰20ä¸ª
            ]
        }
        
        with open("intelligent_validation_report.json", "w") as f:
            json.dump(report, f, indent=2)
        
        if must_fix == 0:
            print("\nâœ… éªŒè¯é€šè¿‡ï¼é¡¹ç›®å·²è¾¾åˆ°å‘å¸ƒæ ‡å‡†ã€‚")
        else:
            print(f"\nâŒ å‘ç° {must_fix} ä¸ªå¿…é¡»ä¿®å¤çš„é—®é¢˜ã€‚")
        
        return report

if __name__ == "__main__":
    validator = IntelligentValidator()
    report = validator.validate()
    
    exit(0 if report["success"] else 1)